{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"ECG_Classification.ipynb","provenance":[]},"accelerator":"GPU"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["\n","from zipfile import ZipFile\n","file_name='/content/MIt-BIH Datasets-20220507T173735Z-001.zip'\n","with ZipFile(file_name,'r') as zip:\n","  zip.extractall()"],"metadata":{"id":"lIYdn1woOS1n","_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-05-08T18:43:29.342001Z","iopub.execute_input":"2022-05-08T18:43:29.342704Z","iopub.status.idle":"2022-05-08T18:43:29.346079Z","shell.execute_reply.started":"2022-05-08T18:43:29.342666Z","shell.execute_reply":"2022-05-08T18:43:29.345089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","MIT_BIH_train = pd.read_csv(\"/content/MIt-BIH Datasets/MIT-BIH-train.csv\" , header = None)\n","MIT_BIH_validate = pd.read_csv(\"/content/MIt-BIH Datasets/MIT-BIH-validate.csv\" , header = None)\n","test = pd.read_csv(\"/content/MIt-BIH Datasets/MIT-BIH-test.csv\" , header = None)"],"metadata":{"id":"7SZcquCkmqva","execution":{"iopub.status.busy":"2022-05-08T18:43:29.383085Z","iopub.execute_input":"2022-05-08T18:43:29.383510Z","iopub.status.idle":"2022-05-08T18:43:36.516785Z","shell.execute_reply.started":"2022-05-08T18:43:29.383477Z","shell.execute_reply":"2022-05-08T18:43:36.516088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["combine = [MIT_BIH_train , MIT_BIH_validate]"],"metadata":{"id":"d_usQIttmqhL","execution":{"iopub.status.busy":"2022-05-08T18:43:36.519208Z","iopub.execute_input":"2022-05-08T18:43:36.519781Z","iopub.status.idle":"2022-05-08T18:43:36.524855Z","shell.execute_reply.started":"2022-05-08T18:43:36.519736Z","shell.execute_reply":"2022-05-08T18:43:36.524244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = pd.concat(combine , axis = 0 )"],"metadata":{"id":"KE9DaQ_bmqXL","execution":{"iopub.status.busy":"2022-05-08T18:43:36.525978Z","iopub.execute_input":"2022-05-08T18:43:36.526302Z","iopub.status.idle":"2022-05-08T18:43:36.598052Z","shell.execute_reply.started":"2022-05-08T18:43:36.526265Z","shell.execute_reply":"2022-05-08T18:43:36.597250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix\n","from keras.utils.np_utils import to_categorical\n","from sklearn.utils import class_weight\n","import warnings\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Reshape\n","from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout,MaxPooling1D\n","from tensorflow.keras.optimizers import Adam \n","from keras.callbacks import LearningRateScheduler\n","\n","import itertools\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, coverage_error\n","\n","from tensorflow.keras.layers import BatchNormalization\n","\n","import imblearn\n","from collections import Counter\n","\n","from sklearn.utils import resample\n","\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"rpZS-C-NmqNO","execution":{"iopub.status.busy":"2022-05-08T18:43:36.600989Z","iopub.execute_input":"2022-05-08T18:43:36.601503Z","iopub.status.idle":"2022-05-08T18:43:36.987482Z","shell.execute_reply.started":"2022-05-08T18:43:36.601465Z","shell.execute_reply":"2022-05-08T18:43:36.986760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.optimizers import Adam , Adadelta"],"metadata":{"id":"pZEv1wLOpfML","execution":{"iopub.status.busy":"2022-05-08T18:43:36.988853Z","iopub.execute_input":"2022-05-08T18:43:36.989152Z","iopub.status.idle":"2022-05-08T18:43:36.995253Z","shell.execute_reply.started":"2022-05-08T18:43:36.989084Z","shell.execute_reply":"2022-05-08T18:43:36.994597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.rename(columns={187:\"Class\"}, inplace=True)\n","test.rename(columns={187:\"Class\"}, inplace=True)"],"metadata":{"id":"mRqyw1mRpfIr","execution":{"iopub.status.busy":"2022-05-08T18:43:36.996108Z","iopub.execute_input":"2022-05-08T18:43:36.996324Z","iopub.status.idle":"2022-05-08T18:43:37.009465Z","shell.execute_reply.started":"2022-05-08T18:43:36.996301Z","shell.execute_reply":"2022-05-08T18:43:37.008649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mapping = {     0. : 'Normal Beat',\n","               1. : 'Supraventricular premature beat',\n","               2. : 'Premature ventricular contraction',\n","               3. : 'Fusion of ventricular',\n","               4. : 'Unclassifiable beat'\n","          }"],"metadata":{"id":"FTt-7Y7HqMI2","execution":{"iopub.status.busy":"2022-05-08T18:43:37.011565Z","iopub.execute_input":"2022-05-08T18:43:37.011781Z","iopub.status.idle":"2022-05-08T18:43:37.018681Z","shell.execute_reply.started":"2022-05-08T18:43:37.011757Z","shell.execute_reply":"2022-05-08T18:43:37.017900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"vC1M_5fHqMB8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["counter = Counter(train['Class'])\n","print(counter)"],"metadata":{"id":"UFWNl2D5pfEH","outputId":"3f68372f-a092-46f9-8888-17b7a0b82c1d","execution":{"iopub.status.busy":"2022-05-08T18:43:37.020300Z","iopub.execute_input":"2022-05-08T18:43:37.020624Z","iopub.status.idle":"2022-05-08T18:43:37.055575Z","shell.execute_reply.started":"2022-05-08T18:43:37.020591Z","shell.execute_reply":"2022-05-08T18:43:37.054683Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Counter({0.0: 89788, 15.0: 7857, 2.0: 7721, 1.0: 5288, 8.0: 3819, 4.0: 2532, 16.0: 1297, 10.0: 653, 12.0: 177, 6.0: 129, 14.0: 93, 5.0: 77, 17.0: 31, 11.0: 21, 7.0: 3})\n"]}]},{"cell_type":"code","source":["df_15=train[train['Class']==15]\n","df_2=train[train['Class']==2]\n","df_1=train[train['Class']==1]\n","df_8=train[train['Class']==8]\n","df_4=train[train['Class']==4]\n","df_16=train[train['Class']==16]\n","df_10=train[train['Class']==10]\n","df_12=train[train['Class']==12]\n","df_6=train[train['Class']==6]\n","df_14=train[train['Class']==14]\n","df_5=train[train['Class']==5]\n","df_17=train[train['Class']==17]\n","df_11=train[train['Class']==11]\n","df_7=train[train['Class']==7]\n","\n","\n","df_0=(train[train['Class']==0]).sample(n=20000,random_state=42)\n","\n","\n","train=pd.concat([df_0,df_15,df_2,df_1,df_8,df_4,df_16,df_10,df_12,df_6,df_14,df_5,df_17,df_11,df_7])"],"metadata":{"id":"kEvWqNpHqQxF","execution":{"iopub.status.busy":"2022-05-08T18:43:37.057049Z","iopub.execute_input":"2022-05-08T18:43:37.057428Z","iopub.status.idle":"2022-05-08T18:43:37.262651Z","shell.execute_reply.started":"2022-05-08T18:43:37.057334Z","shell.execute_reply":"2022-05-08T18:43:37.261927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tain_count_classes_resamble =train[\"Class\"].value_counts()"],"metadata":{"id":"SUSQq0s2qQoK","execution":{"iopub.status.busy":"2022-05-08T18:43:37.265818Z","iopub.execute_input":"2022-05-08T18:43:37.266098Z","iopub.status.idle":"2022-05-08T18:43:37.273230Z","shell.execute_reply.started":"2022-05-08T18:43:37.266067Z","shell.execute_reply":"2022-05-08T18:43:37.272333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train=train.iloc[:,:186].values\n","X_test=test.iloc[:,:186].values"],"metadata":{"id":"oI7MkdrAttA6","execution":{"iopub.status.busy":"2022-05-08T18:43:37.274648Z","iopub.execute_input":"2022-05-08T18:43:37.274906Z","iopub.status.idle":"2022-05-08T18:43:37.283088Z","shell.execute_reply.started":"2022-05-08T18:43:37.274873Z","shell.execute_reply":"2022-05-08T18:43:37.282484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"zLnmEtKxMu6t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from imblearn.over_sampling import SMOTE\n","oversample = SMOTE(k_neighbors=2)\n","X_train, y_train = oversample.fit_resample(X_train, train[\"Class\"])\n"],"metadata":{"id":"MOAHToQRtx3z","execution":{"iopub.status.busy":"2022-05-08T18:43:37.284332Z","iopub.execute_input":"2022-05-08T18:43:37.284654Z","iopub.status.idle":"2022-05-08T18:43:41.519959Z","shell.execute_reply.started":"2022-05-08T18:43:37.284621Z","shell.execute_reply":"2022-05-08T18:43:41.519138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["counter = Counter(y_train)\n","print(counter)"],"metadata":{"id":"LQ0Fyn6EuqQ4","outputId":"b418e6f9-c391-4b98-e0fc-b48083686805","execution":{"iopub.status.busy":"2022-05-08T18:43:41.521955Z","iopub.execute_input":"2022-05-08T18:43:41.522363Z","iopub.status.idle":"2022-05-08T18:43:41.590946Z","shell.execute_reply.started":"2022-05-08T18:43:41.522327Z","shell.execute_reply":"2022-05-08T18:43:41.589632Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Counter({0.0: 20000, 15.0: 20000, 2.0: 20000, 1.0: 20000, 8.0: 20000, 4.0: 20000, 16.0: 20000, 10.0: 20000, 12.0: 20000, 6.0: 20000, 14.0: 20000, 5.0: 20000, 17.0: 20000, 11.0: 20000, 7.0: 20000})\n"]}]},{"cell_type":"code","source":["X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n","X_test = X_test.reshape(len(X_test), X_test.shape[1],1)"],"metadata":{"id":"wdfemNZgup5T","execution":{"iopub.status.busy":"2022-05-08T18:43:41.592347Z","iopub.execute_input":"2022-05-08T18:43:41.592824Z","iopub.status.idle":"2022-05-08T18:43:41.611074Z","shell.execute_reply.started":"2022-05-08T18:43:41.592788Z","shell.execute_reply":"2022-05-08T18:43:41.610305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_test=test[\"Class\"]\n","y_train=y_train\n","y_test=target_test\n"],"metadata":{"id":"3rLn5ysYuz-T","execution":{"iopub.status.busy":"2022-05-08T18:43:41.612763Z","iopub.execute_input":"2022-05-08T18:43:41.613278Z","iopub.status.idle":"2022-05-08T18:43:41.620237Z","shell.execute_reply.started":"2022-05-08T18:43:41.613241Z","shell.execute_reply":"2022-05-08T18:43:41.619432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train= np.array(y_train).reshape(-1,1)\n","y_test= np.array(y_test).reshape(-1,1)\n","from sklearn.preprocessing import OneHotEncoder\n","enc = OneHotEncoder()\n","encoder_df1 = pd.DataFrame(enc.fit_transform(y_train).toarray())\n","encoder_df2 = pd.DataFrame(enc.fit_transform(y_test).toarray())\n","y_train = np.array(encoder_df1)\n","y_test = np.array(encoder_df2)"],"metadata":{"execution":{"iopub.status.busy":"2022-05-08T18:43:41.621515Z","iopub.execute_input":"2022-05-08T18:43:41.622009Z","iopub.status.idle":"2022-05-08T18:43:41.715908Z","shell.execute_reply.started":"2022-05-08T18:43:41.621974Z","shell.execute_reply":"2022-05-08T18:43:41.715169Z"},"trusted":true,"id":"p_FQCUCwMu6v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_labels_ytr = np.argmax(y_train, axis=1)\n","class_labels_yte = np.argmax(y_test, axis=1)\n"],"metadata":{"execution":{"iopub.status.busy":"2022-05-08T18:43:41.717351Z","iopub.execute_input":"2022-05-08T18:43:41.717589Z","iopub.status.idle":"2022-05-08T18:43:41.730342Z","shell.execute_reply.started":"2022-05-08T18:43:41.717552Z","shell.execute_reply":"2022-05-08T18:43:41.729494Z"},"trusted":true,"id":"NZ8V38fsMu6v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"id":"bTn3XcYhuz8C","outputId":"a3bb9184-52aa-4832-df82-9eda9da074d5","execution":{"iopub.status.busy":"2022-05-08T18:43:41.731992Z","iopub.execute_input":"2022-05-08T18:43:41.732525Z","iopub.status.idle":"2022-05-08T18:43:41.738353Z","shell.execute_reply.started":"2022-05-08T18:43:41.732486Z","shell.execute_reply":"2022-05-08T18:43:41.737506Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300000, 186, 1)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["n_obs, feature, depth = X_train.shape\n","batch_size = 500"],"metadata":{"id":"jqjEqNx3uz5l","execution":{"iopub.status.busy":"2022-05-08T18:43:41.740304Z","iopub.execute_input":"2022-05-08T18:43:41.740888Z","iopub.status.idle":"2022-05-08T18:43:41.746447Z","shell.execute_reply.started":"2022-05-08T18:43:41.740849Z","shell.execute_reply":"2022-05-08T18:43:41.745563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test.shape"],"metadata":{"id":"W4CjPagVvEQn","outputId":"1f1aebfd-5482-4f4b-af02-b9090993b336","execution":{"iopub.status.busy":"2022-05-08T18:43:41.748244Z","iopub.execute_input":"2022-05-08T18:43:41.748655Z","iopub.status.idle":"2022-05-08T18:43:41.757073Z","shell.execute_reply.started":"2022-05-08T18:43:41.748619Z","shell.execute_reply":"2022-05-08T18:43:41.756180Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(29872, 186, 1)"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["y_train.shape"],"metadata":{"execution":{"iopub.status.busy":"2022-05-08T18:43:41.758510Z","iopub.execute_input":"2022-05-08T18:43:41.758814Z","iopub.status.idle":"2022-05-08T18:43:41.766806Z","shell.execute_reply.started":"2022-05-08T18:43:41.758724Z","shell.execute_reply":"2022-05-08T18:43:41.765930Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"r38Fds3-Mu6w","outputId":"66564f00-606e-4d0f-bebc-83db332dc8bc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(300000, 15)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["y_test.shape"],"metadata":{"execution":{"iopub.status.busy":"2022-05-08T18:43:41.768435Z","iopub.execute_input":"2022-05-08T18:43:41.769640Z","iopub.status.idle":"2022-05-08T18:43:41.776060Z","shell.execute_reply.started":"2022-05-08T18:43:41.769574Z","shell.execute_reply":"2022-05-08T18:43:41.775146Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"gXCbk5UcMu6w","outputId":"dbb58cec-6797-4a8b-c014-4873d4e4780e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(29872, 15)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["X_train=X_train.reshape(300000, 186,1)\n","X_test=X_test.reshape(29872, 186,1)"],"metadata":{"id":"NPhU-wL1uz2h","execution":{"iopub.status.busy":"2022-05-08T18:43:41.777548Z","iopub.execute_input":"2022-05-08T18:43:41.778566Z","iopub.status.idle":"2022-05-08T18:43:41.783724Z","shell.execute_reply.started":"2022-05-08T18:43:41.778525Z","shell.execute_reply":"2022-05-08T18:43:41.782747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def exp_decay(epoch):\n","    initial_lrate = 0.001\n","    k = 0.75\n","    t = n_obs//(10000 * batch_size)  # every epoch we do n_obs/batch_size iteration\n","    lrate = initial_lrate * np.math.exp(-k*t)\n","    return lrate"],"metadata":{"id":"3kzvGyUIuzyO","execution":{"iopub.status.busy":"2022-05-08T18:43:41.785193Z","iopub.execute_input":"2022-05-08T18:43:41.785768Z","iopub.status.idle":"2022-05-08T18:43:41.792233Z","shell.execute_reply.started":"2022-05-08T18:43:41.785731Z","shell.execute_reply":"2022-05-08T18:43:41.791591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = Adadelta(lr=.001)"],"metadata":{"id":"8rBmEHayvPcr","execution":{"iopub.status.busy":"2022-05-08T18:43:41.793446Z","iopub.execute_input":"2022-05-08T18:43:41.794200Z","iopub.status.idle":"2022-05-08T18:43:41.806568Z","shell.execute_reply.started":"2022-05-08T18:43:41.794082Z","shell.execute_reply":"2022-05-08T18:43:41.805932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lrate = LearningRateScheduler(exp_decay)"],"metadata":{"id":"aHL-VU72vPOw","execution":{"iopub.status.busy":"2022-05-08T18:43:41.807587Z","iopub.execute_input":"2022-05-08T18:43:41.807807Z","iopub.status.idle":"2022-05-08T18:43:41.813488Z","shell.execute_reply.started":"2022-05-08T18:43:41.807775Z","shell.execute_reply":"2022-05-08T18:43:41.812051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_callbacks = [\n","#    keras.callbacks.EarlyStopping(monitor='val_loss' , patience=8),\n","    keras.callbacks.ModelCheckpoint(filepath='cnn_model.h5' , monitor = 'val_loss' , save_best_only=True),\n","    lrate\n","]"],"metadata":{"id":"Gm7RX_x0ATVL","execution":{"iopub.status.busy":"2022-05-08T18:43:41.815109Z","iopub.execute_input":"2022-05-08T18:43:41.815631Z","iopub.status.idle":"2022-05-08T18:43:41.821896Z","shell.execute_reply.started":"2022-05-08T18:43:41.815386Z","shell.execute_reply":"2022-05-08T18:43:41.821165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train=y_train[0:300000]\n","y_test=y_test[0:29872]"],"metadata":{"id":"4sONmU3_vPKD","execution":{"iopub.status.busy":"2022-05-08T18:43:41.826485Z","iopub.execute_input":"2022-05-08T18:43:41.827168Z","iopub.status.idle":"2022-05-08T18:43:41.831206Z","shell.execute_reply.started":"2022-05-08T18:43:41.827134Z","shell.execute_reply":"2022-05-08T18:43:41.830463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"o-glczx1xbKI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(y_train.shape)\n","print(X_train.shape)\n","print(y_test.shape)\n","print(X_test.shape)"],"metadata":{"id":"nf81RTCpvj7q","outputId":"6ea00dc5-af4e-4e10-d08f-a3dcdc5061b6","execution":{"iopub.status.busy":"2022-05-08T18:43:41.832420Z","iopub.execute_input":"2022-05-08T18:43:41.833111Z","iopub.status.idle":"2022-05-08T18:43:41.840498Z","shell.execute_reply.started":"2022-05-08T18:43:41.833068Z","shell.execute_reply":"2022-05-08T18:43:41.839507Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(300000, 15)\n","(300000, 186, 1)\n","(29872, 15)\n","(29872, 186, 1)\n"]}]},{"cell_type":"code","source":["'''\n","# Applying the function to training set labels and testing set labels\n","from tensorflow.keras.utils import to_categorical\n","y_train = to_categorical(y_train )\n","y_test = to_categorical(y_test)\n","'''"],"metadata":{"id":"x1BM0HVbxcxx","outputId":"b60c39c1-03d9-407f-9685-4b08cc61d4bb","execution":{"iopub.status.busy":"2022-05-08T18:43:41.843414Z","iopub.execute_input":"2022-05-08T18:43:41.843590Z","iopub.status.idle":"2022-05-08T18:43:41.851915Z","shell.execute_reply.started":"2022-05-08T18:43:41.843568Z","shell.execute_reply":"2022-05-08T18:43:41.851139Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":53}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# Applying the function to training set labels and testing set labels\\nfrom tensorflow.keras.utils import to_categorical\\ny_train = to_categorical(y_train )\\ny_test = to_categorical(y_test)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":[""],"metadata":{"id":"BC-uFcEdyHgf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n","from tensorflow.keras.losses import sparse_categorical_crossentropy\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import KFold ,  StratifiedKFold\n","import numpy as np"],"metadata":{"id":"XdWwqME3vojR","execution":{"iopub.status.busy":"2022-05-08T18:43:41.853150Z","iopub.execute_input":"2022-05-08T18:43:41.853533Z","iopub.status.idle":"2022-05-08T18:43:41.858953Z","shell.execute_reply.started":"2022-05-08T18:43:41.853496Z","shell.execute_reply":"2022-05-08T18:43:41.858248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc_per_fold = []\n","loss_per_fold = []\n","\n","inputs = np.concatenate((X_train, X_test), axis=0)\n","targets = np.concatenate((y_train, y_test), axis=0)\n"],"metadata":{"id":"KZPjwZEszPCf","execution":{"iopub.status.busy":"2022-05-08T18:43:41.860222Z","iopub.execute_input":"2022-05-08T18:43:41.860790Z","iopub.status.idle":"2022-05-08T18:43:42.059905Z","shell.execute_reply.started":"2022-05-08T18:43:41.860729Z","shell.execute_reply":"2022-05-08T18:43:42.058983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(inputs.shape)"],"metadata":{"id":"UpgovcwrzRBe","outputId":"32b1c620-7b64-4f9c-a7fb-8e78f9b21a97","execution":{"iopub.status.busy":"2022-05-08T18:43:42.062217Z","iopub.execute_input":"2022-05-08T18:43:42.062640Z","iopub.status.idle":"2022-05-08T18:43:42.067059Z","shell.execute_reply.started":"2022-05-08T18:43:42.062599Z","shell.execute_reply":"2022-05-08T18:43:42.066376Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(329872, 186, 1)\n"]}]},{"cell_type":"code","source":["print(targets.shape)"],"metadata":{"id":"KeV1PrlNzZHU","outputId":"7a075817-48df-4234-9713-1954f82c4fd3","execution":{"iopub.status.busy":"2022-05-08T18:43:42.068577Z","iopub.execute_input":"2022-05-08T18:43:42.069049Z","iopub.status.idle":"2022-05-08T18:43:42.076185Z","shell.execute_reply.started":"2022-05-08T18:43:42.069013Z","shell.execute_reply":"2022-05-08T18:43:42.075095Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(329872, 15)\n"]}]},{"cell_type":"code","source":["\n","skf = StratifiedKFold(n_splits=5, shuffle=True)\n","\n","fold_no = 1\n","for train , test in skf.split(inputs, np.argmax(targets,axis=1)):\n","    \n","  model = Sequential()\n","\n","  model.add(Convolution1D(filters=32, kernel_size=5, strides=1 , input_shape=(186,1)))\n","  model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation='relu'))\n","  model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation = 'relu'))\n","  model.add(MaxPooling1D(pool_size=5, strides=2))\n","\n","  model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation='relu'))\n","  model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation = 'relu'))\n","  model.add(MaxPooling1D(pool_size=5, strides=2))\n","\n","  model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation='relu'))\n","  model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation = 'relu'))\n","  model.add(MaxPooling1D(pool_size=5, strides=2))\n","\n","  model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation='relu'))\n","  model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation = 'relu'))\n","  model.add(MaxPooling1D(pool_size=5, strides=2))\n","\n","  model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation='relu'))\n","  model.add(Convolution1D(filters=32, kernel_size=5, strides=1, padding='same' , activation = 'relu'))\n","  model.add(MaxPooling1D(pool_size=5, strides=2))\n","\n","  model.add(Flatten())\n","\n","  model.add(Dense(512, activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(Dense(256, activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(Dense(64, activation='relu'))\n","  model.add(BatchNormalization())\n","\n","\n","  model.add(Dense(15, activation='softmax'))\n","\n","  model.compile(optimizer='Adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n"," \n","  # Generate a print\n","  print('------------------------------------------------------------------------')\n","  print(f'Training for fold {fold_no} ...')\n","\n","  # Fit data to model\n","  history = model.fit(inputs[train], targets[train],\n","              batch_size=500,\n","              epochs=75,\n","              verbose=1)\n","\n","  # Generate generalization metrics\n","  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n","  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n","  acc_per_fold.append(scores[1] * 100)\n","  loss_per_fold.append(scores[0])\n","\n","  # Increase fold number\n","  fold_no = fold_no + 1"],"metadata":{"id":"V49PYZodvoic","outputId":"0470e96b-644d-48b0-a99e-1b6fdc4fc9fb","execution":{"iopub.status.busy":"2022-05-08T18:43:42.078316Z","iopub.execute_input":"2022-05-08T18:43:42.078796Z","iopub.status.idle":"2022-05-08T19:36:13.786907Z","shell.execute_reply.started":"2022-05-08T18:43:42.078759Z","shell.execute_reply":"2022-05-08T19:36:13.786146Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------\n","Training for fold 1 ...\n","Epoch 1/75\n","528/528 [==============================] - 20s 16ms/step - loss: 2.4122 - accuracy: 0.2783\n","Epoch 2/75\n","528/528 [==============================] - 8s 15ms/step - loss: 1.6341 - accuracy: 0.5272\n","Epoch 3/75\n","528/528 [==============================] - 8s 15ms/step - loss: 1.3259 - accuracy: 0.6458\n","Epoch 4/75\n","528/528 [==============================] - 8s 15ms/step - loss: 1.1411 - accuracy: 0.7031\n","Epoch 5/75\n","528/528 [==============================] - 8s 15ms/step - loss: 1.0116 - accuracy: 0.7424\n","Epoch 6/75\n","528/528 [==============================] - 8s 15ms/step - loss: 0.9108 - accuracy: 0.7735\n","Epoch 7/75\n","528/528 [==============================] - 8s 15ms/step - loss: 0.8330 - accuracy: 0.7958\n","Epoch 8/75\n","528/528 [==============================] - 8s 15ms/step - loss: 0.7703 - accuracy: 0.8123\n","Epoch 9/75\n","528/528 [==============================] - 8s 15ms/step - loss: 0.7185 - accuracy: 0.8250\n","Epoch 10/75\n","528/528 [==============================] - 8s 15ms/step - loss: 0.6748 - accuracy: 0.8369\n","Epoch 11/75\n","528/528 [==============================] - 8s 15ms/step - loss: 0.6374 - accuracy: 0.8471\n","Epoch 12/75\n","528/528 [==============================] - 8s 15ms/step - loss: 0.6045 - accuracy: 0.8562\n","Epoch 13/75\n","528/528 [==============================] - 8s 15ms/step - loss: 0.5758 - accuracy: 0.8639\n","Epoch 14/75\n","528/528 [==============================] - 8s 15ms/step - loss: 0.5499 - accuracy: 0.8706\n","Epoch 15/75\n","528/528 [==============================] - 8s 15ms/step - loss: 0.5266 - accuracy: 0.8766\n","Epoch 16/75\n","528/528 [==============================] - 8s 15ms/step - loss: 0.5051 - accuracy: 0.8821\n","Epoch 17/75\n","528/528 [==============================] - 8s 15ms/step - loss: 0.4858 - accuracy: 0.8867\n","Epoch 18/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4684 - accuracy: 0.8910\n","Epoch 19/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4521 - accuracy: 0.8950\n","Epoch 20/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4376 - accuracy: 0.8988\n","Epoch 21/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4238 - accuracy: 0.9024\n","Epoch 22/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4113 - accuracy: 0.9054\n","Epoch 23/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3995 - accuracy: 0.9085\n","Epoch 24/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3884 - accuracy: 0.9107\n","Epoch 25/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3782 - accuracy: 0.9132\n","Epoch 26/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3688 - accuracy: 0.9156\n","Epoch 27/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3598 - accuracy: 0.9174\n","Epoch 28/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3511 - accuracy: 0.9198\n","Epoch 29/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3431 - accuracy: 0.9217\n","Epoch 30/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3353 - accuracy: 0.9233\n","Epoch 31/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3280 - accuracy: 0.9252\n","Epoch 32/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3217 - accuracy: 0.9265\n","Epoch 33/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3147 - accuracy: 0.9280\n","Epoch 34/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3086 - accuracy: 0.9295\n","Epoch 35/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3025 - accuracy: 0.9305\n","Epoch 36/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2968 - accuracy: 0.9319\n","Epoch 37/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2914 - accuracy: 0.9330\n","Epoch 38/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2861 - accuracy: 0.9340\n","Epoch 39/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2813 - accuracy: 0.9351\n","Epoch 40/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2765 - accuracy: 0.9361\n","Epoch 41/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2716 - accuracy: 0.9370\n","Epoch 42/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2673 - accuracy: 0.9378\n","Epoch 43/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2628 - accuracy: 0.9387\n","Epoch 44/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2586 - accuracy: 0.9398\n","Epoch 45/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2547 - accuracy: 0.9404\n","Epoch 46/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2504 - accuracy: 0.9416\n","Epoch 47/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2469 - accuracy: 0.9418\n","Epoch 48/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2433 - accuracy: 0.9427\n","Epoch 49/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2396 - accuracy: 0.9435\n","Epoch 50/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2359 - accuracy: 0.9444\n","Epoch 51/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2326 - accuracy: 0.9450\n","Epoch 52/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2296 - accuracy: 0.9457\n","Epoch 53/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2262 - accuracy: 0.9464\n","Epoch 54/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2230 - accuracy: 0.9473\n","Epoch 55/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2201 - accuracy: 0.9479\n","Epoch 56/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2173 - accuracy: 0.9486\n","Epoch 57/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2144 - accuracy: 0.9491\n","Epoch 58/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2118 - accuracy: 0.9497\n","Epoch 59/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2092 - accuracy: 0.9500\n","Epoch 60/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2063 - accuracy: 0.9506\n","Epoch 61/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2041 - accuracy: 0.9513\n","Epoch 62/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2015 - accuracy: 0.9518\n","Epoch 63/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1991 - accuracy: 0.9523\n","Epoch 64/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1968 - accuracy: 0.9529\n","Epoch 65/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1946 - accuracy: 0.9535\n","Epoch 66/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1922 - accuracy: 0.9541\n","Epoch 67/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1903 - accuracy: 0.9541\n","Epoch 68/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1882 - accuracy: 0.9547\n","Epoch 69/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1860 - accuracy: 0.9553\n","Epoch 70/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1840 - accuracy: 0.9556\n","Epoch 71/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1824 - accuracy: 0.9560\n","Epoch 72/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1802 - accuracy: 0.9566\n","Epoch 73/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1782 - accuracy: 0.9566\n","Epoch 74/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1763 - accuracy: 0.9574\n","Epoch 75/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1747 - accuracy: 0.9577\n","Score for fold 1: loss of 0.17708514630794525; accuracy of 95.63319683074951%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Epoch 1/75\n","528/528 [==============================] - 10s 16ms/step - loss: 2.4509 - accuracy: 0.2533\n","Epoch 2/75\n","528/528 [==============================] - 8s 16ms/step - loss: 1.5842 - accuracy: 0.5706\n","Epoch 3/75\n","528/528 [==============================] - 8s 16ms/step - loss: 1.2813 - accuracy: 0.6649\n","Epoch 4/75\n","528/528 [==============================] - 8s 16ms/step - loss: 1.0999 - accuracy: 0.7182\n","Epoch 5/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.9746 - accuracy: 0.7541\n","Epoch 6/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.8814 - accuracy: 0.7805\n","Epoch 7/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.8084 - accuracy: 0.8009\n","Epoch 8/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.7495 - accuracy: 0.8180\n","Epoch 9/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.7009 - accuracy: 0.8312\n","Epoch 10/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.6586 - accuracy: 0.8429\n","Epoch 11/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.6216 - accuracy: 0.8519\n","Epoch 12/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.5883 - accuracy: 0.8598\n","Epoch 13/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.5587 - accuracy: 0.8675\n","Epoch 14/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.5325 - accuracy: 0.8749\n","Epoch 15/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.5088 - accuracy: 0.8815\n","Epoch 16/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4871 - accuracy: 0.8874\n","Epoch 17/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4674 - accuracy: 0.8924\n","Epoch 18/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4494 - accuracy: 0.8968\n","Epoch 19/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4329 - accuracy: 0.9010\n","Epoch 20/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4181 - accuracy: 0.9045\n","Epoch 21/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4039 - accuracy: 0.9083\n","Epoch 22/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3909 - accuracy: 0.9116\n","Epoch 23/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3789 - accuracy: 0.9143\n","Epoch 24/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3677 - accuracy: 0.9171\n","Epoch 25/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3577 - accuracy: 0.9194\n","Epoch 26/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3479 - accuracy: 0.9215\n","Epoch 27/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3389 - accuracy: 0.9237\n","Epoch 28/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3306 - accuracy: 0.9254\n","Epoch 29/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3225 - accuracy: 0.9276\n","Epoch 30/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3149 - accuracy: 0.9293\n","Epoch 31/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3078 - accuracy: 0.9306\n","Epoch 32/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3011 - accuracy: 0.9324\n","Epoch 33/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2946 - accuracy: 0.9336\n","Epoch 34/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2887 - accuracy: 0.9349\n","Epoch 35/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2827 - accuracy: 0.9365\n","Epoch 36/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2769 - accuracy: 0.9378\n","Epoch 37/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2717 - accuracy: 0.9387\n","Epoch 38/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2665 - accuracy: 0.9399\n","Epoch 39/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2614 - accuracy: 0.9411\n","Epoch 40/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2568 - accuracy: 0.9419\n","Epoch 41/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2519 - accuracy: 0.9429\n","Epoch 42/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2476 - accuracy: 0.9439\n","Epoch 43/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2433 - accuracy: 0.9447\n","Epoch 44/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2392 - accuracy: 0.9457\n","Epoch 45/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2353 - accuracy: 0.9464\n","Epoch 46/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2315 - accuracy: 0.9470\n","Epoch 47/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2276 - accuracy: 0.9480\n","Epoch 48/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2245 - accuracy: 0.9484\n","Epoch 49/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2211 - accuracy: 0.9493\n","Epoch 50/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2177 - accuracy: 0.9502\n","Epoch 51/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2144 - accuracy: 0.9508\n","Epoch 52/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2115 - accuracy: 0.9513\n","Epoch 53/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2084 - accuracy: 0.9520\n","Epoch 54/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2055 - accuracy: 0.9524\n","Epoch 55/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2027 - accuracy: 0.9531\n","Epoch 56/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2001 - accuracy: 0.9538\n","Epoch 57/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1975 - accuracy: 0.9543\n","Epoch 58/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1948 - accuracy: 0.9549\n","Epoch 59/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1922 - accuracy: 0.9553\n","Epoch 60/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1898 - accuracy: 0.9557\n","Epoch 61/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1875 - accuracy: 0.9564\n","Epoch 62/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1853 - accuracy: 0.9564\n","Epoch 63/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1827 - accuracy: 0.9572\n","Epoch 64/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1809 - accuracy: 0.9574\n","Epoch 65/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1786 - accuracy: 0.9581\n","Epoch 66/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1767 - accuracy: 0.9584\n","Epoch 67/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1745 - accuracy: 0.9589\n","Epoch 68/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1726 - accuracy: 0.9594\n","Epoch 69/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1704 - accuracy: 0.9597\n","Epoch 70/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1686 - accuracy: 0.9601\n","Epoch 71/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1666 - accuracy: 0.9605\n","Epoch 72/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1650 - accuracy: 0.9608\n","Epoch 73/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1633 - accuracy: 0.9613\n","Epoch 74/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1615 - accuracy: 0.9615\n","Epoch 75/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1598 - accuracy: 0.9619\n","Score for fold 2: loss of 0.15541546046733856; accuracy of 96.21068835258484%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Epoch 1/75\n","528/528 [==============================] - 10s 17ms/step - loss: 2.4319 - accuracy: 0.2732\n","Epoch 2/75\n","528/528 [==============================] - 8s 16ms/step - loss: 1.5761 - accuracy: 0.5631\n","Epoch 3/75\n","528/528 [==============================] - 8s 16ms/step - loss: 1.2713 - accuracy: 0.6652\n","Epoch 4/75\n","528/528 [==============================] - 8s 16ms/step - loss: 1.0936 - accuracy: 0.7211\n","Epoch 5/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.9723 - accuracy: 0.7574\n","Epoch 6/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.8801 - accuracy: 0.7830\n","Epoch 7/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.8081 - accuracy: 0.8026\n","Epoch 8/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.7493 - accuracy: 0.8187\n","Epoch 9/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.7005 - accuracy: 0.8304\n","Epoch 10/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.6597 - accuracy: 0.8396\n","Epoch 11/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.6254 - accuracy: 0.8476\n","Epoch 12/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.5957 - accuracy: 0.8546\n","Epoch 13/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.5690 - accuracy: 0.8608\n","Epoch 14/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.5456 - accuracy: 0.8661\n","Epoch 15/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.5239 - accuracy: 0.8712\n","Epoch 16/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.5047 - accuracy: 0.8759\n","Epoch 17/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4878 - accuracy: 0.8801\n","Epoch 18/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4717 - accuracy: 0.8841\n","Epoch 19/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4570 - accuracy: 0.8879\n","Epoch 20/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4436 - accuracy: 0.8914\n","Epoch 21/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4310 - accuracy: 0.8947\n","Epoch 22/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4193 - accuracy: 0.8977\n","Epoch 23/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4083 - accuracy: 0.9003\n","Epoch 24/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3978 - accuracy: 0.9030\n","Epoch 25/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3879 - accuracy: 0.9058\n","Epoch 26/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3785 - accuracy: 0.9080\n","Epoch 27/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3699 - accuracy: 0.9105\n","Epoch 28/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3615 - accuracy: 0.9123\n","Epoch 29/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3531 - accuracy: 0.9146\n","Epoch 30/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3458 - accuracy: 0.9165\n","Epoch 31/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3383 - accuracy: 0.9185\n","Epoch 32/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3316 - accuracy: 0.9204\n","Epoch 33/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3248 - accuracy: 0.9218\n","Epoch 34/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3187 - accuracy: 0.9233\n","Epoch 35/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.3127 - accuracy: 0.9249\n","Epoch 36/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3066 - accuracy: 0.9263\n","Epoch 37/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3012 - accuracy: 0.9273\n","Epoch 38/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2956 - accuracy: 0.9288\n","Epoch 39/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2909 - accuracy: 0.9296\n","Epoch 40/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2856 - accuracy: 0.9311\n","Epoch 41/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2808 - accuracy: 0.9321\n","Epoch 42/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2762 - accuracy: 0.9334\n","Epoch 43/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2716 - accuracy: 0.9344\n","Epoch 44/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2674 - accuracy: 0.9352\n","Epoch 45/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2632 - accuracy: 0.9362\n","Epoch 46/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2590 - accuracy: 0.9368\n","Epoch 47/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2550 - accuracy: 0.9381\n","Epoch 48/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2513 - accuracy: 0.9387\n","Epoch 49/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2477 - accuracy: 0.9397\n","Epoch 50/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2441 - accuracy: 0.9405\n","Epoch 51/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2408 - accuracy: 0.9412\n","Epoch 52/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2371 - accuracy: 0.9420\n","Epoch 53/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2340 - accuracy: 0.9427\n","Epoch 54/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2307 - accuracy: 0.9436\n","Epoch 55/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2277 - accuracy: 0.9443\n","Epoch 56/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2248 - accuracy: 0.9449\n","Epoch 57/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2221 - accuracy: 0.9457\n","Epoch 58/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2189 - accuracy: 0.9462\n","Epoch 59/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2162 - accuracy: 0.9471\n","Epoch 60/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2136 - accuracy: 0.9477\n","Epoch 61/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2109 - accuracy: 0.9483\n","Epoch 62/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2084 - accuracy: 0.9488\n","Epoch 63/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2057 - accuracy: 0.9496\n","Epoch 64/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2033 - accuracy: 0.9501\n","Epoch 65/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2009 - accuracy: 0.9507\n","Epoch 66/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1985 - accuracy: 0.9514\n","Epoch 67/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1965 - accuracy: 0.9517\n","Epoch 68/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1940 - accuracy: 0.9523\n","Epoch 69/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1919 - accuracy: 0.9530\n","Epoch 70/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1898 - accuracy: 0.9536\n","Epoch 71/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1877 - accuracy: 0.9538\n","Epoch 72/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.1857 - accuracy: 0.9544\n","Epoch 73/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1838 - accuracy: 0.9546\n","Epoch 74/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1817 - accuracy: 0.9553\n","Epoch 75/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1801 - accuracy: 0.9558\n","Score for fold 3: loss of 0.18254275619983673; accuracy of 95.48307061195374%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Epoch 1/75\n","528/528 [==============================] - 10s 16ms/step - loss: 2.4770 - accuracy: 0.2667\n","Epoch 2/75\n","528/528 [==============================] - 8s 16ms/step - loss: 1.6730 - accuracy: 0.5179\n","Epoch 3/75\n","528/528 [==============================] - 8s 16ms/step - loss: 1.3776 - accuracy: 0.6193\n","Epoch 4/75\n","528/528 [==============================] - 8s 16ms/step - loss: 1.1948 - accuracy: 0.6745\n","Epoch 5/75\n","528/528 [==============================] - 8s 16ms/step - loss: 1.0646 - accuracy: 0.7108\n","Epoch 6/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.9671 - accuracy: 0.7385\n","Epoch 7/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.8911 - accuracy: 0.7620\n","Epoch 8/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.8288 - accuracy: 0.7808\n","Epoch 9/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.7772 - accuracy: 0.7967\n","Epoch 10/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.7323 - accuracy: 0.8109\n","Epoch 11/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.6942 - accuracy: 0.8222\n","Epoch 12/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.6609 - accuracy: 0.8319\n","Epoch 13/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.6311 - accuracy: 0.8402\n","Epoch 14/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.6047 - accuracy: 0.8478\n","Epoch 15/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.5807 - accuracy: 0.8543\n","Epoch 16/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.5581 - accuracy: 0.8606\n","Epoch 17/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.5372 - accuracy: 0.8672\n","Epoch 18/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.5182 - accuracy: 0.8725\n","Epoch 19/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.5000 - accuracy: 0.8775\n","Epoch 20/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4835 - accuracy: 0.8824\n","Epoch 21/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4676 - accuracy: 0.8863\n","Epoch 22/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4532 - accuracy: 0.8900\n","Epoch 23/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4391 - accuracy: 0.8937\n","Epoch 24/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4264 - accuracy: 0.8973\n","Epoch 25/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4140 - accuracy: 0.9006\n","Epoch 26/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.4026 - accuracy: 0.9037\n","Epoch 27/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3917 - accuracy: 0.9065\n","Epoch 28/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3815 - accuracy: 0.9093\n","Epoch 29/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3715 - accuracy: 0.9120\n","Epoch 30/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3622 - accuracy: 0.9145\n","Epoch 31/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3535 - accuracy: 0.9169\n","Epoch 32/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3448 - accuracy: 0.9194\n","Epoch 33/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3372 - accuracy: 0.9213\n","Epoch 34/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3295 - accuracy: 0.9236\n","Epoch 35/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3224 - accuracy: 0.9251\n","Epoch 36/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.3157 - accuracy: 0.9266\n","Epoch 37/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.3089 - accuracy: 0.9282\n","Epoch 38/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.3029 - accuracy: 0.9297\n","Epoch 39/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2969 - accuracy: 0.9311\n","Epoch 40/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2909 - accuracy: 0.9326\n","Epoch 41/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2854 - accuracy: 0.9341\n","Epoch 42/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2800 - accuracy: 0.9353\n","Epoch 43/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2750 - accuracy: 0.9363\n","Epoch 44/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2701 - accuracy: 0.9378\n","Epoch 45/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2656 - accuracy: 0.9388\n","Epoch 46/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2610 - accuracy: 0.9398\n","Epoch 47/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2567 - accuracy: 0.9410\n","Epoch 48/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2524 - accuracy: 0.9418\n","Epoch 49/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2482 - accuracy: 0.9429\n","Epoch 50/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2442 - accuracy: 0.9438\n","Epoch 51/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2409 - accuracy: 0.9442\n","Epoch 52/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2370 - accuracy: 0.9452\n","Epoch 53/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2333 - accuracy: 0.9461\n","Epoch 54/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2298 - accuracy: 0.9467\n","Epoch 55/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2265 - accuracy: 0.9476\n","Epoch 56/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2232 - accuracy: 0.9483\n","Epoch 57/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2200 - accuracy: 0.9491\n","Epoch 58/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2170 - accuracy: 0.9495\n","Epoch 59/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2142 - accuracy: 0.9501\n","Epoch 60/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2114 - accuracy: 0.9508\n","Epoch 61/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2084 - accuracy: 0.9513\n","Epoch 62/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2058 - accuracy: 0.9519\n","Epoch 63/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2033 - accuracy: 0.9524\n","Epoch 64/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.2004 - accuracy: 0.9533\n","Epoch 65/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1983 - accuracy: 0.9534\n","Epoch 66/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1958 - accuracy: 0.9542\n","Epoch 67/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.1934 - accuracy: 0.9548\n","Epoch 68/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1910 - accuracy: 0.9552\n","Epoch 69/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.1889 - accuracy: 0.9556\n","Epoch 70/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.1865 - accuracy: 0.9561\n","Epoch 71/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1844 - accuracy: 0.9566\n","Epoch 72/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.1823 - accuracy: 0.9571\n","Epoch 73/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.1806 - accuracy: 0.9574\n","Epoch 74/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.1787 - accuracy: 0.9577\n","Epoch 75/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.1765 - accuracy: 0.9581\n","Score for fold 4: loss of 0.18111537396907806; accuracy of 95.63161134719849%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Epoch 1/75\n","528/528 [==============================] - 10s 16ms/step - loss: 2.4310 - accuracy: 0.2729\n","Epoch 2/75\n","528/528 [==============================] - 8s 16ms/step - loss: 1.6187 - accuracy: 0.5622\n","Epoch 3/75\n","528/528 [==============================] - 8s 16ms/step - loss: 1.3144 - accuracy: 0.6543\n","Epoch 4/75\n","528/528 [==============================] - 8s 16ms/step - loss: 1.1423 - accuracy: 0.6968\n","Epoch 5/75\n","528/528 [==============================] - 8s 16ms/step - loss: 1.0241 - accuracy: 0.7305\n","Epoch 6/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.9340 - accuracy: 0.7578\n","Epoch 7/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.8630 - accuracy: 0.7795\n","Epoch 8/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.8040 - accuracy: 0.7977\n","Epoch 9/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.7543 - accuracy: 0.8133\n","Epoch 10/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.7118 - accuracy: 0.8253\n","Epoch 11/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.6737 - accuracy: 0.8370\n","Epoch 12/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.6400 - accuracy: 0.8473\n","Epoch 13/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.6095 - accuracy: 0.8562\n","Epoch 14/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.5819 - accuracy: 0.8638\n","Epoch 15/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.5569 - accuracy: 0.8704\n","Epoch 16/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.5340 - accuracy: 0.8767\n","Epoch 17/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.5128 - accuracy: 0.8818\n","Epoch 18/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.4933 - accuracy: 0.8867\n","Epoch 19/75\n","528/528 [==============================] - 8s 16ms/step - loss: 0.4753 - accuracy: 0.8911\n","Epoch 20/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.4585 - accuracy: 0.8949\n","Epoch 21/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.4433 - accuracy: 0.8984\n","Epoch 22/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.4290 - accuracy: 0.9014\n","Epoch 23/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.4161 - accuracy: 0.9045\n","Epoch 24/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.4038 - accuracy: 0.9073\n","Epoch 25/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.3920 - accuracy: 0.9096\n","Epoch 26/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.3818 - accuracy: 0.9123\n","Epoch 27/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.3716 - accuracy: 0.9148\n","Epoch 28/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.3620 - accuracy: 0.9169\n","Epoch 29/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.3531 - accuracy: 0.9191\n","Epoch 30/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.3441 - accuracy: 0.9213\n","Epoch 31/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.3363 - accuracy: 0.9230\n","Epoch 32/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.3286 - accuracy: 0.9247\n","Epoch 33/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.3214 - accuracy: 0.9263\n","Epoch 34/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.3147 - accuracy: 0.9277\n","Epoch 35/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.3083 - accuracy: 0.9292\n","Epoch 36/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.3018 - accuracy: 0.9304\n","Epoch 37/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2957 - accuracy: 0.9320\n","Epoch 38/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2902 - accuracy: 0.9332\n","Epoch 39/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2850 - accuracy: 0.9340\n","Epoch 40/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2795 - accuracy: 0.9353\n","Epoch 41/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2747 - accuracy: 0.9361\n","Epoch 42/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2697 - accuracy: 0.9372\n","Epoch 43/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2653 - accuracy: 0.9382\n","Epoch 44/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2611 - accuracy: 0.9390\n","Epoch 45/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2566 - accuracy: 0.9400\n","Epoch 46/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2524 - accuracy: 0.9408\n","Epoch 47/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2489 - accuracy: 0.9415\n","Epoch 48/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2447 - accuracy: 0.9424\n","Epoch 49/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2412 - accuracy: 0.9432\n","Epoch 50/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2374 - accuracy: 0.9441\n","Epoch 51/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2338 - accuracy: 0.9446\n","Epoch 52/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2303 - accuracy: 0.9456\n","Epoch 53/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2270 - accuracy: 0.9463\n","Epoch 54/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2240 - accuracy: 0.9468\n","Epoch 55/75\n","528/528 [==============================] - 9s 17ms/step - loss: 0.2205 - accuracy: 0.9478\n","Epoch 56/75\n","528/528 [==============================] - 9s 17ms/step - loss: 0.2175 - accuracy: 0.9485\n","Epoch 57/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2147 - accuracy: 0.9489\n","Epoch 58/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2119 - accuracy: 0.9496\n","Epoch 59/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2090 - accuracy: 0.9502\n","Epoch 60/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2062 - accuracy: 0.9509\n","Epoch 61/75\n","528/528 [==============================] - 9s 17ms/step - loss: 0.2037 - accuracy: 0.9513\n","Epoch 62/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.2009 - accuracy: 0.9522\n","Epoch 63/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.1986 - accuracy: 0.9527\n","Epoch 64/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.1961 - accuracy: 0.9533\n","Epoch 65/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.1936 - accuracy: 0.9539\n","Epoch 66/75\n","528/528 [==============================] - 9s 17ms/step - loss: 0.1911 - accuracy: 0.9543\n","Epoch 67/75\n","528/528 [==============================] - 9s 17ms/step - loss: 0.1887 - accuracy: 0.9549\n","Epoch 68/75\n","528/528 [==============================] - 9s 17ms/step - loss: 0.1867 - accuracy: 0.9556\n","Epoch 69/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.1846 - accuracy: 0.9558\n","Epoch 70/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.1823 - accuracy: 0.9566\n","Epoch 71/75\n","528/528 [==============================] - 9s 17ms/step - loss: 0.1803 - accuracy: 0.9571\n","Epoch 72/75\n","528/528 [==============================] - 9s 17ms/step - loss: 0.1782 - accuracy: 0.9576\n","Epoch 73/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.1765 - accuracy: 0.9579\n","Epoch 74/75\n","528/528 [==============================] - 9s 16ms/step - loss: 0.1744 - accuracy: 0.9581\n","Epoch 75/75\n","528/528 [==============================] - 9s 17ms/step - loss: 0.1724 - accuracy: 0.9586\n","Score for fold 5: loss of 0.17264527082443237; accuracy of 95.88322639465332%\n"]}]},{"cell_type":"code","source":["from statistics import mean\n","mean(acc_per_fold)"],"metadata":{"id":"ByAVEQf5voeV","execution":{"iopub.status.busy":"2022-05-08T19:36:13.799209Z","iopub.execute_input":"2022-05-08T19:36:13.799514Z","iopub.status.idle":"2022-05-08T19:36:13.808586Z","shell.execute_reply.started":"2022-05-08T19:36:13.799480Z","shell.execute_reply":"2022-05-08T19:36:13.807738Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"55149e14-2e8e-49d1-b857-8ee804ab7377"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["95.76835870742798"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["\n","from numpy import std\n","# Accuracy in SKFold\n","acc_per_fold\n"],"metadata":{"id":"Qc6rW_ptytJi","execution":{"iopub.status.busy":"2022-05-08T19:36:13.788406Z","iopub.execute_input":"2022-05-08T19:36:13.788660Z","iopub.status.idle":"2022-05-08T19:36:13.797587Z","shell.execute_reply.started":"2022-05-08T19:36:13.788625Z","shell.execute_reply":"2022-05-08T19:36:13.796720Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fca2a5c2-9ad0-4bd2-a642-936d23eb1df4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[95.63319683074951,\n"," 96.21068835258484,\n"," 95.48307061195374,\n"," 95.63161134719849,\n"," 95.88322639465332]"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["print('min value element : ')\n","min(acc_per_fold)\n"],"metadata":{"id":"obNHTHmpvodc","execution":{"iopub.status.busy":"2022-05-08T19:36:13.810247Z","iopub.execute_input":"2022-05-08T19:36:13.810520Z","iopub.status.idle":"2022-05-08T19:36:13.817758Z","shell.execute_reply.started":"2022-05-08T19:36:13.810483Z","shell.execute_reply":"2022-05-08T19:36:13.816881Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b61df62a-4e77-4cc6-cbef-b7f1c5b03743"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["min value element : \n"]},{"output_type":"execute_result","data":{"text/plain":["95.48307061195374"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["print(\"Max value element : \")\n","max(acc_per_fold)"],"metadata":{"id":"kz169-O-voPu","execution":{"iopub.status.busy":"2022-05-08T19:36:13.819276Z","iopub.execute_input":"2022-05-08T19:36:13.819815Z","iopub.status.idle":"2022-05-08T19:36:13.826516Z","shell.execute_reply.started":"2022-05-08T19:36:13.819775Z","shell.execute_reply":"2022-05-08T19:36:13.825598Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"04b632b7-4f83-46ff-f1d7-9dd7f736a609"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Max value element : \n"]},{"output_type":"execute_result","data":{"text/plain":["96.21068835258484"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["import statistics\n","st_dev = statistics.pstdev(acc_per_fold)\n","print(\"Standard deviation of the given list: \" + str(st_dev))"],"metadata":{"id":"SPo6Urlby30e","execution":{"iopub.status.busy":"2022-05-08T19:36:13.828222Z","iopub.execute_input":"2022-05-08T19:36:13.828784Z","iopub.status.idle":"2022-05-08T19:36:13.834948Z","shell.execute_reply.started":"2022-05-08T19:36:13.828742Z","shell.execute_reply":"2022-05-08T19:36:13.834173Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2d20d5e6-203d-4c04-e2e9-b51271c40b0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Standard deviation of the given list: 0.2558155473810743\n"]}]},{"cell_type":"code","source":["# loss in SKFold\n","loss_per_fold"],"metadata":{"id":"-vS6hKX3y3rx","execution":{"iopub.status.busy":"2022-05-08T19:36:13.836458Z","iopub.execute_input":"2022-05-08T19:36:13.836953Z","iopub.status.idle":"2022-05-08T19:36:13.843962Z","shell.execute_reply.started":"2022-05-08T19:36:13.836917Z","shell.execute_reply":"2022-05-08T19:36:13.843242Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a393b41c-2975-4c92-eada-70f9ad30fcc3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.17708514630794525,\n"," 0.15541546046733856,\n"," 0.18254275619983673,\n"," 0.18111537396907806,\n"," 0.17264527082443237]"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["print('mean in loss: ')\n","mean(loss_per_fold)"],"metadata":{"id":"6NA0tq2Wy9nq","execution":{"iopub.status.busy":"2022-05-08T19:36:13.845610Z","iopub.execute_input":"2022-05-08T19:36:13.846278Z","iopub.status.idle":"2022-05-08T19:36:13.855352Z","shell.execute_reply.started":"2022-05-08T19:36:13.846239Z","shell.execute_reply":"2022-05-08T19:36:13.854675Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f6ffa0f-6408-43be-fc80-44af5f3e613d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mean in loss: \n"]},{"output_type":"execute_result","data":{"text/plain":["0.1737608015537262"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["print('min value element : ')\n","min(loss_per_fold)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9ILM4xAeSgD","outputId":"a732bb75-d657-47d7-b87a-f0b2e06b8c24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["min value element : \n"]},{"output_type":"execute_result","data":{"text/plain":["0.15541546046733856"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["print(\"Max value element : \")\n","max(loss_per_fold)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tviRZoQbevJv","outputId":"b375eb78-932c-47a7-f169-d23782de029f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Max value element : \n"]},{"output_type":"execute_result","data":{"text/plain":["0.18254275619983673"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["import statistics\n","st_dev = statistics.pstdev(loss_per_fold)\n","print(\"Standard deviation of the given list: \" + str(st_dev))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XM6ICG_2eSKs","outputId":"de59cb59-4c71-40d4-ebf6-7eeb2b33cdf7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Standard deviation of the given list: 0.009798568050973589\n"]}]}]}